{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26fced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入 bokeh.plotting 作为 bpl，用于交互式数据可视化\n",
    "import bokeh.plotting as bpl\n",
    "\n",
    "# 引入 cv2，常用于计算机视觉任务\n",
    "import cv2  \n",
    "\n",
    "# 引入 glob，用于文件路径名的模式匹配\n",
    "import glob  \n",
    "\n",
    "# 从 IPython 导入 get_ipython，用于处理 IPython 内核的命令\n",
    "from IPython import get_ipython \n",
    "\n",
    "# 引入 logging，用于记录日志信息\n",
    "import logging \n",
    "\n",
    "# 引入 matplotlib.pyplot 作为 plt，用于绘制图形和进行数据可视化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 引入 numpy 作为 np，是 Python 的科学计算包\n",
    "import numpy as np\n",
    "\n",
    "# 引入 os，提供了与操作系统交互的功能\n",
    "import os \n",
    "\n",
    "# 尝试设置 cv2 的线程数为 0，以优化性能\n",
    "try:\n",
    "    cv2.setNumThreads(0)  \n",
    "except():\n",
    "    pass\n",
    "\n",
    "# 尝试在 IPython 环境中自动重新加载模块\n",
    "try:\n",
    "    if __IPYTHON__:        \n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload') \n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "except NameError:  # 如果不在 IPython 环境中，则不执行任何操作\n",
    "    pass\n",
    "\n",
    "# 引入 caiman 作为 cm，这是一个用于钙信号数据分析的包\n",
    "import caiman as cm  \n",
    "\n",
    "# 从 caiman.motion_correction 导入 MotionCorrect，用于运动校正\n",
    "from caiman.motion_correction import MotionCorrect      \n",
    "\n",
    "# 从 caiman.source_extraction.cnmf 导入 cnmf 和 params，用于源提取和参数设置\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "\n",
    "# 从 caiman.utils.utils 导入 download_demo，用于下载演示数据\n",
    "from caiman.utils.utils import download_demo      \n",
    "\n",
    "# 从 caiman.utils.visualization 导入绘制工具，用于数据的可视化\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "\n",
    "# 设置 bokeh 输出到 Jupyter notebook\n",
    "bpl.output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b726f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 logging 包进行日志管理\n",
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\", # 可以指定日志文件的路径和文件名，这里被注释掉了\n",
    "                    level=logging.WARNING) # 设置日志级别为 WARNING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b84180-2734-43da-a84a-e5b85e76625f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_demo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 如果 fnames 列表中的第一個元素是 '1_mcor.tif' 或 'demoMovie.tif'，則執行以下操作\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 此行代碼用於檢查 '1_mcor.tif' 和 'demoMovie.tif' 是否為目標文件，若是，則將它們關聯起來\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fnames[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1_mcor.tif\u001b[39m\u001b[38;5;124m'\u001b[39m]: \n\u001b[1;32m----> 6\u001b[0m     fnames \u001b[38;5;241m=\u001b[39m [\u001b[43mdownload_demo\u001b[49m(fnames[\u001b[38;5;241m0\u001b[39m])]  \u001b[38;5;66;03m# 使用 download_demo 函數下載對應的演示文件\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'download_demo' is not defined"
     ]
    }
   ],
   "source": [
    "fnames = ['1_mcor.tif']  # 要處理的文件名\n",
    "\n",
    "# 如果 fnames 列表中的第一個元素是 '1_mcor.tif' 或 'demoMovie.tif'，則執行以下操作\n",
    "# 此行代碼用於檢查 '1_mcor.tif' 和 'demoMovie.tif' 是否為目標文件，若是，則將它們關聯起來\n",
    "if fnames[0] in ['1_mcor.tif']: \n",
    "    fnames = [download_demo(fnames[0])]  # 使用 download_demo 函數下載對應的演示文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae792d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_movie = True  # 定義一個布林變量 display_movie，並設定其初始值為 True\n",
    "if display_movie:  # 如果 display_movie 為 True，則執行下面的代碼塊\n",
    "    m_orig = cm.load_movie_chain(fnames)  # 使用 caiman 包中的 load_movie_chain 函數載入電影鏈\n",
    "    ds_ratio = 0.2  # 設定一個下採樣比率 ds_ratio 為 0.2\n",
    "    m_orig.resize(1, 1, ds_ratio).play(  # 調整原始電影 m_orig 的大小，使用下採樣比率 ds_ratio，對載入的電影進行縮放並播放\n",
    "        q_max=99.5, fr=30, magnification=2)  # 播放時設置最大品質 q_max 為 99.5，幀率 fr 為 30，放大倍數為 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48361658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = 10                     # 影像速率，单位是每秒幀數\n",
    "decay_time = 0.4            # 典型瞬态的持续时间，单位是秒\n",
    "\n",
    "# motion correction parameters\n",
    "\n",
    "strides = (48, 48)          # 每隔x像素开始一个新的pw-rigid运动校正补丁\n",
    "overlaps = (24, 24)         # 补丁之间的重叠部分（补丁大小为strides+overlaps）\n",
    "max_shifts = (6,6)          # 允许的最大刚性位移（以像素为单位）\n",
    "max_deviation_rigid = 3     # 允许的针对刚性位移的最大补丁偏移\n",
    "pw_rigid = True             # 执行非刚性运动校正的标志\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = 1                       # 自回归系统的阶数\n",
    "gnb = 2                     # 全局背景成分的数量\n",
    "merge_thr = 0.85            # 合并阈值，允许的最大相关性\n",
    "rf = 15                     # 补丁的半尺寸，单位是像素。例如，如果rf=25，则补丁为50x50\n",
    "stride_cnmf = 6             # 补丁之间的重叠量，单位是像素\n",
    "K = 4                       # 每个补丁的组件数\n",
    "gSig = [4, 4]               # 预期神经元的半尺寸，单位是像素\n",
    "method_init = 'greedy_roi'  # 初始化方法（如果使用'sparse_nmf'分析树突数据）\n",
    "ssub = 1                    # 初始化期间的空间子采样\n",
    "tsub = 1                    # 初始化期间的时间子采样\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.0               # 接受一个组件的信噪比\n",
    "rval_thr = 0.85             # 接受一个组件的空间相关性阈值\n",
    "cnn_thr = 0.99              # 基于CNN的分类器的阈值\n",
    "cnn_lowest = 0.1            # CNN概率低于此值的神经元将被拒绝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義一個參數字典，用於配置 CNMF 算法的各項參數\n",
    "opts_dict = {\n",
    "    'fnames': fnames,  # 文件名列表，用於指定要分析的影像文件\n",
    "    'fr': fr,  # 影像的幀率（每秒幀數）\n",
    "    'decay_time': decay_time,  # 信號衰減的時間\n",
    "    'strides': strides,  # 在執行局部分解時的步長\n",
    "    'overlaps': overlaps,  # 局部區域之間的重疊部分\n",
    "    'max_shifts': max_shifts,  # 最大移動修正量（用於校正影像移動）\n",
    "    'max_deviation_rigid': max_deviation_rigid,  # 剛性移動的最大偏差\n",
    "    'pw_rigid': pw_rigid,  # 是否使用片段剛性移動修正\n",
    "    'p': p,  # AR(p)模型中的參數p，用於時間序列的預測和去噪\n",
    "    'nb': gnb,  # 背景成分的數量\n",
    "    'rf': rf,  # 局部區域的半徑\n",
    "    'K': K,  # 搜索的神經元數量\n",
    "    'gSig': gSig,  # 空間過濾器的標準差\n",
    "    'stride': stride_cnmf,  # 在執行 CNMF 時的步長\n",
    "    'method_init': method_init,  # 初始化方法\n",
    "    'rolling_sum': True,  # 是否使用滾動總和來估計背景\n",
    "    'only_init': True,  # 是否只進行初始化，不執行後續分析\n",
    "    'ssub': ssub,  # 空間上的降採樣因子\n",
    "    'tsub': tsub,  # 時間上的降採樣因子\n",
    "    'merge_thr': merge_thr,  # 合併閾值，用於合併相似的神經元成分\n",
    "    'min_SNR': min_SNR,  # 最小信噪比，用於神經元分量的篩選\n",
    "    'rval_thr': rval_thr,  # 相關性閾值，用於篩選神經元分量\n",
    "    'use_cnn': True,  # 是否使用卷積神經網路進行分量篩選\n",
    "    'min_cnn_thr': cnn_thr,  # CNN 篩選的最小閾值\n",
    "    'cnn_lowest': cnn_lowest  # CNN 篩選的最低閾值\n",
    "}\n",
    "\n",
    "# 使用提供的參數字典創建 CNMF 參數對象\n",
    "opts = params.CNMFParams(params_dict=opts_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 開始一個用於並行處理的集群（如果已經存在一個集群，它將被關閉並開啟一個新的會話）\n",
    "# 檢查 'dview' 變量是否在本地變量中。'dview' 通常用於代表當前的分佈式視圖\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)   # 如果存在，則停止服務器並關閉當前集群\n",
    "\n",
    "# 設置新的集群。這裡使用 'cm.cluster.setup_cluster' 方法來配置和啟動一個新的集群\n",
    "# backend='multiprocessing' 表示使用多進程後台進行並行計算\n",
    "# n_processes=None 表示使用所有可用的處理器核心\n",
    "# single_thread=False 表示每個進程可以使用多個線程\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing', n_processes=None, single_thread=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc80329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先我們根據指定的參數創建一個運動校正對象\n",
    "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))\n",
    "# 注意，文件並未加載到內存中\n",
    "\n",
    "# 解釋：\n",
    "# `MotionCorrect` 是一個類別，用於運動校正。它通常用於處理視頻或圖像序列中的運動造成的扭曲。\n",
    "# `fnames` 可能是一個文件名列表，代表要處理的視頻或圖像文件。\n",
    "# `dview` 是一個分佈式處理視圖對象，用於並行處理。如果不提供，運動校正可能只在單個核心上運行。\n",
    "# `opts.get_group('motion')` 可能是一個獲取運動校正相關參數的方法，`opts` 是一個配置對象，包含了不同處理步驟所需的參數。\n",
    "# 註釋中提到的“文件並未加載到內存中”意味著運動校正過程是按需加載文件的，而不是一次性將所有文件加載到內存中，這有助於處理大文件或長視頻。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f33928-afe2-4b44-a385-2a9969af947a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<caiman.motion_correction.MotionCorrect at 0x1e33863a200>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393eb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# %%capture 可以捕捉并隐藏cell输出的魔法命令\n",
    "\n",
    "#%% Run piecewise-rigid motion correction using NoRMCorre\n",
    "# 使用 NoRMCorre 执行逐片刚性运动校正\n",
    "mc.motion_correct(save_movie=True)\n",
    "# mc.motion_correct 是一个运动校正方法，save_movie=True 表示保存校正后的影像\n",
    "\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "# cm.load 加载处理后的影像数据，mc.fname_tot_els 是校正后影像的文件名\n",
    "\n",
    "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0 \n",
    "# 设置边界值。如果 mc.border_nan 等于 'copy'，则边界设为0，否则使用 mc.border_to_0 的值\n",
    "# 这里的 border_nan 和 border_to_0 是处理影像边界时使用的参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% compare with original movie 比較原始電影\n",
    "display_movie = True  # 設定是否顯示電影\n",
    "if display_movie:  # 如果需要顯示電影\n",
    "    m_orig = cm.load_movie_chain(fnames)  # 加載原始電影數據，'cm' 可能是一个用於处理电影数据的包\n",
    "    ds_ratio = 0.2  # 設定縮小比例，这里是将电影数据下采样（减少数据量）以便处理\n",
    "    # 下面这行代码合并了调整大小后的原始电影和处理后的电影，然后进行播放\n",
    "    cm.concatenate([m_orig.resize(1, 1, ds_ratio) - mc.min_mov*mc.nonneg_movie,\n",
    "                    m_els.resize(1, 1, ds_ratio)], \n",
    "                   axis=2).play(fr=60, gain=15, magnification=2, offset=0)  # 按 q 退出播放\n",
    "    # 'cm.concatenate' 是合併兩個電影數據的函數\n",
    "    # 'resize' 函数改变电影数据的大小\n",
    "    # 'play' 函数用于播放合并后的电影，'fr' 是帧率, 'gain' 是增益, 'magnification' 是放大倍数, 'offset' 是偏移量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f55bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% MEMORY MAPPING\n",
    "# memory map the file in order 'C'\n",
    "fname_new = cm.save_memmap(mc.mmap_file, base_name='NT5-1', # name change\n",
    "                           order='C', border_to_0=border_to_0, dview=dview) \n",
    "    # 將檔案以 'C' 順序映射到記憶體中\n",
    "    # cm.save_memmap 是用來儲存記憶體映射檔案的函數，mc.mmap_file 是要映射的檔案\n",
    "    # base_name='NT5-1' 表示設定映射檔案的基本名稱，order='C' 表示以C語言風格的行主序來儲存陣列\n",
    "    # border_to_0 和 dview 是額外的參數，用於控制映射過程\n",
    "\n",
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "    # 加載剛才創建的記憶體映射檔案\n",
    "    # cm.load_memmap 是用來加載記憶體映射檔案的函數\n",
    "    # Yr 是映射檔案的數據陣列，dims 是數據的維度，T 是時間軸的長度\n",
    "\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "    # 將加載的數據重新排列成圖像格式 (時間軸 x 寬度 x 高度)\n",
    "    # np.reshape 是 NumPy 函數，用於重新排列數據的形狀\n",
    "    # Yr.T 是對 Yr 進行轉置，使得時間軸 T 成為第一維\n",
    "    # [T] + list(dims) 設定了新的數據形狀，order='F' 表示以Fortran風格的列主序來儲存陣列\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442847c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 重啟集群以清理記憶體\n",
    "cm.stop_server(dview=dview)  # 呼叫 cm (caiman) 套件停止伺服器，釋放由 'dview' 指定的資源\n",
    "\n",
    "# 設定集群\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing',  # 使用 'multiprocessing' 作為後端\n",
    "    n_processes=None,  # 自動決定進程數量\n",
    "    single_thread=False)  # 設定為多線程模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af140b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# 使用 %%capture 魔術指令來捕捉該單元格的輸出，防止輸出太多信息到屏幕上\n",
    "\n",
    "#%% RUN CNMF ON PATCHES\n",
    "# 在小片段上運行 CNMF（Constrained Nonnegative Matrix Factorization，受限非負矩陣分解）\n",
    "# 首先在小片段上提取空間和時間組件，然後將它們結合起來\n",
    "# 在這個步驟中，去捲積被關閉（p=0）。如果你想在每個小片段內進行去捲積，\n",
    "# 可以將 params.patch['p_patch'] 的值改為非零\n",
    "\n",
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)  # 創建 CNMF 對象\n",
    "cnm = cnm.fit(images)  # 對圖像應用 CNMF，提取空間和時間組件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% plot contours of found components\n",
    "# 繪製發現的組件的輪廓\n",
    "\n",
    "# cm 是用於分析和處理視頻數據的一個庫，這裡的 local_correlations 函數計算影像的局部相關性\n",
    "Cn = cm.local_correlations(images.transpose(1,2,0))\n",
    "\n",
    "# 處理任何NaN值（不是數值），將它們設置為0，以便進行穩定的影像處理\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "\n",
    "# cnm 是一個用於鈣信號分析的對象。這裡的 estimates.plot_contours_nb 函數繪製影像Cn上發現的組件的輪廓\n",
    "cnm.estimates.plot_contours_nb(img=Cn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55499824",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# 使用 %%capture 魔法命令來捕獲此單元格的輸出，以防止其顯示在Jupyter Notebook的輸出中。\n",
    "\n",
    "#%% RE-RUN seeded CNMF （限制非负矩阵分解） on accepted patches to refine and perform deconvolution \n",
    "# 重新运行带有种子的CNMF（Constrained Non-negative Matrix Factorization，限制非负矩阵分解）在接受的补丁上以精炼和执行去卷积。\n",
    "# 这是用于图像或视频数据的一种分析方法，特别适用于神经成像数据。\n",
    "\n",
    "cnm2 = cnm.refit(images, dview=dview)\n",
    "# 使用 refit 方法对图像进行再拟合，以优化之前的CNMF模型。\n",
    "# 'images' 是要处理的图像数据。\n",
    "# 'dview' 是一个用于并行计算的视图对象，可能是与并行处理库（如ipyparallel）相关的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585cbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这段代码中，使用了 CNMF（限制非负矩阵分解）的方法。这是一种分析技术，通常用于神经科学领域，\n",
    "# 尤其是在处理类似于脑部成像数据的复杂数据集时。它能够从这些数据中提取有用的信号，这在研究神\n",
    "# 经元活动时特别重要。代码中的 refit 方法用于优化和改进之前的CNMF分析结果，这在处理动态或时\n",
    "# 变数据时非常有用。同时，使用并行视图对象 dview 可以加速这个过程，特别是在处理大量数据时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70485f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# 這部分代碼是用於評估組件的\n",
    "# 組件的評估有三種方式：\n",
    "#   a) 每個組件的形狀必須與數據相關聯\n",
    "#   b) 在瞬變事件的長度上需要一個最小的峰值信噪比\n",
    "#   c) 每個形狀都要通過基於CNN的分類器\n",
    "\n",
    "cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6992ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "# 使用 cnm2.estimates.plot_contours_nb 函数来绘制轮廓图。\n",
    "# img 参数设置为 Cn，这通常是一个背景图像或相关参考图像。\n",
    "# idx 参数设置为 cnm2.estimates.idx_components，表示我们要在图像上标出的特定组件的索引。\n",
    "cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "# cnm2.estimates.nb_view_components() 函式用於显示组件的图像\n",
    "# 'img=Cn' 参数代表要显示的图像\n",
    "# 'idx=cnm2.estimates.idx_components' 参数指定要显示的组件的索引\n",
    "cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf36f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "# 檢查被拒絕的組件\n",
    "if len(cnm2.estimates.idx_components_bad) > 0:\n",
    "    # 若存在被拒絕的組件，則顯示它們\n",
    "    cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components_bad)\n",
    "else:\n",
    "    # 若無被拒絕的組件，則輸出相應信息\n",
    "    print(\"No components were rejected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ffb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Extract DF/F values\n",
    "# 提取 ΔF/F 值\n",
    "# ΔF/F 是一个常用于神经科学中的计算方法，用于表示钙信号的相对变化。\n",
    "# 这个步骤通常在钙影像数据分析中非常重要，用于量化神经元活动。\n",
    "\n",
    "cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250);\n",
    "# cnm2 是一个对象，通常与钙影像数据分析库（如CaImAn）相关。\n",
    "# .estimates 是CaImAn中用于存储和处理估计结果的属性。\n",
    "# detrend_df_f() 是一个方法，用于去除趋势并计算 ΔF/F。\n",
    "# quantileMin 参数设置去趋势时使用的最小分位数。\n",
    "# frames_window 参数定义了用于计算基线的帧窗口大小。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4410ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 cnm2 的 estimates 属性中的 select_components 方法\n",
    "# 选择特定的组件。此处设置 use_object=True 表明使用面向对象的方式进行选择。\n",
    "cnm2.estimates.select_components(use_object=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb67ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的包\n",
    "# cnm2 专门的图像处理或神经网络模型库的实例或对象\n",
    "\n",
    "# 使用 cnm2 的 estimates 属性中的 nb_view_components 方法\n",
    "# 这个方法用于查看图像组件\n",
    "# 参数 img=Cn 指定要处理的图像\n",
    "# 参数 denoised_color='red' 指定去噪声后的颜色显示为红色\n",
    "cnm2.estimates.nb_view_components(img=Cn, denoised_color='red')\n",
    "\n",
    "# 打印提示信息\n",
    "# 提示可能需要改变数据传输率以生成图像\n",
    "# 使用 Jupyter Notebook 时，通过设置 --NotebookApp.iopub_data_rate_limit=1.0e 来调整\n",
    "print('you may need to change the data rate to generate this one: use jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 save_results 設定為 True，以決定是否儲存結果\n",
    "save_results = True\n",
    "\n",
    "# 如果 save_results 為 True，則執行儲存操作\n",
    "if save_results:\n",
    "    # 使用 cnm2.save 函數將分析結果儲存為 HDF5 格式的文件\n",
    "    # HDF5 格式是一種用於儲存大量科學數據的文件格式\n",
    "    cnm2.save('analysis_results.hdf5')   # 存储路径：C:\\Users\\HSH Lab\\analysis_results.hdf5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 停止集群并清理日志文件\n",
    "# 使用 `cm.stop_server` 方法停止服务器。这里的 `dview` 变量可能是与集群服务器相关的一个参数。\n",
    "cm.stop_server(dview=dview)\n",
    "\n",
    "# 寻找当前目录下所有符合 '*_LOG_*' 模式的文件。这通常用于匹配特定的日志文件。\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "\n",
    "# 遍历找到的日志文件列表\n",
    "for log_file in log_files:\n",
    "    # 删除每一个日志文件。使用 `os.remove` 函数来删除文件。\n",
    "    os.remove(log_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87042c-a8cf-47c3-bd45-7b93b133bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.play_movie(images, q_max=99.9, gain_res=2,\n",
    "                                  magnification=2,\n",
    "                                  bpx=border_to_0,\n",
    "                                  include_bck=False);\n",
    "\n",
    "# 使用cnm2模块的estimates.play_movie函数进行电影处理\n",
    "# images - 传入的电影帧数据\n",
    "# q_max - 可选参数，表示质量因子的最大值，默认为99.9\n",
    "# gain_res - 可选参数，表示增益因子的分辨率，默认为2\n",
    "# magnification - 可选参数，表示放大倍数，默认为2\n",
    "# bpx - 可选参数，表示边界像素，默认为border_to_0\n",
    "# include_bck - 可选参数，是否包括背景处理，默认为False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4a93c-bb74-4a03-a54a-6fc5e049e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie 使用cm.movie函数对信号进行去噪\n",
    "denoised = cm.movie(cnm2.estimates.A.dot(cnm2.estimates.C) + \\\n",
    "                    cnm2.estimates.b.dot(cnm2.estimates.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码中使用的包/模块的功能解释：\n",
    "# - cm：自定义的包，用于处理电影数据，可能包含了去噪功能。\n",
    "# - cnm2：这个包或模块可能包含了一些关于非负矩阵分解（NMF）的估计，如A、C、b和f等参数的估计。\n",
    "# - dot：这是一个矩阵相乘的函数，用于计算A.dot(C)和b.dot(f)的结果。\n",
    "# - reshape：这个函数用于改变数组的形状，将计算结果调整成dims的形状。\n",
    "# - order='F'：这是reshape函数的参数，表示使用Fortran风格的顺序重新排列数组元素。\n",
    "# - transpose：这个函数用于交换数组的轴，将结果调整成所需的形状，[2, 0, 1]表示交换轴的顺序。\n",
    "\n",
    "# 请注意，具体的功能和用法可能需要根据上下文和实际代码的用途来确认。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a82aa3-4480-4904-b653-12565d4fa14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import caiman as cm\n",
    "\n",
    "# 确保cnm2是CNMF算法运行后的结果对象, cnm2.estimates.A和cnm2.estimates.C计算好\n",
    "\n",
    "# 获取重建的电影数据\n",
    "reconstructed_movie = cm.movie(cnm2.estimates.A.dot(cnm2.estimates.C))\n",
    "\n",
    "# 将重建的电影转换为NumPy数组\n",
    "reconstructed_movie_array = np.array(reconstructed_movie)\n",
    "\n",
    "images = []\n",
    "\n",
    "# 遍历每一帧，将其转换为PIL图像，并添加到列表中\n",
    "for i in range(reconstructed_movie_array.shape[0]):\n",
    "    frame = reconstructed_movie_array[i]\n",
    "    images.append(Image.fromarray(frame.astype(np.uint8)))\n",
    "\n",
    "# 确保至少有一帧图像\n",
    "if images:\n",
    "    # 保存第一帧，并将其余帧作为TIF文件的其他页\n",
    "    tif_path = 'reconstructed_movie.tif'\n",
    "    images[0].save(tif_path, save_all=True, append_images=images[1:], compression=\"tiff_deflate\")\n",
    "\n",
    "print(f\"The reconstructed movie has been saved to {tif_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c757d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3356e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2738293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447ab58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca4deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7bfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
